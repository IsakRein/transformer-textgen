{
  "model": "rnn",
  "tokenizer": "char",
  "m": 100,
  "learning_rate": 0.001,
  "seq_length": 25,
  "batch_size": 1,
  "gradient_clip": 5,
  "smooth_loss_factor": 0.999,
  "n_iters": 100000,
  "log_every": 1000,
  "syntesize_every": 10000
}
